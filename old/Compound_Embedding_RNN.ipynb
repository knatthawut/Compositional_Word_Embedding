{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from gensim.models import Word2Vec\n",
    "import functools\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cont declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_Word2Vec_model = 'SG'\n",
    "vector_file_name = 'wiki-db_more50_200'\n",
    "vector_file_name_path = './../model/' + type_of_Word2Vec_model + '/' + vector_file_name\n",
    "MAX_SEQUENCE_LENGTH = 21\n",
    "num_of_epochs = 5\n",
    "batch_size = 1024 \n",
    "\n",
    "train_file_name = 'uni_pair_combine'\n",
    "train_file_path = './../dataset/train_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "num_hidden = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file_name,wordvec):\n",
    "    '''\n",
    "    Create training data for the network.\n",
    "    Input:\n",
    "    Output: x_train , y_train\n",
    "    '''\n",
    "    # initiate the return values\n",
    "    \n",
    "    #Read data\n",
    "    fin = open(input_file_name,'r', encoding = 'utf-8').read().split('\\n')\n",
    "#     print('First sentence: ', fin[0])\n",
    "    num_of_train_sample = len(fin)\n",
    "    \n",
    "    # Initiate the return values\n",
    "    y_train = []\n",
    "    x_train = []\n",
    "\n",
    "    # Load data\n",
    "    count = 0\n",
    "    with open(input_file_name,'r', encoding = 'utf-8') as fin:\n",
    "        for line in fin:\n",
    "            tmp = line.split('\\t')\n",
    "            y_string = tmp[0]\n",
    "#             x_string = tmp[1].lower().strip('\\n').split(' ')\n",
    "            if y_string.lower() in wordvec.wv:\n",
    "                y_train.append(wordvec.wv[y_string])\n",
    "            else:\n",
    "                y_train.append(wordvec.wv['UNKNOWN'])\n",
    "            # change Text into Integer\n",
    "#             x_train_line = []\n",
    "#             for sample in x_string:\n",
    "#                 if sample in wordvec.wv:\n",
    "#                     x_train_line.append(wordvec.wv.vocab[sample].index)\n",
    "#                 else:\n",
    "#                     x_train_line.append(wordvec.wv.vocab['unknown'].index)\n",
    "#             x_train.append(x_train_line)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Padding\n",
    "#     x_train = pad_sequences(x_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # return x_train, y_train\n",
    "    return x_train , y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word2VecTOEmbeddingMatrix(wordvec, embedding_dim):\n",
    "    model = wordvec\n",
    "    embedding_matrix = np.zeros((len(model.wv.vocab), embedding_dim))\n",
    "    for i in range(len(model.wv.vocab)):\n",
    "        embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Simple RNN network without attention\n",
    "def init_rnn_model(vocab_size, embedding_dim, embedding_matrix, MAX_SEQUENCE_LENGTH ):\n",
    "    model =  Sequential() # Define Sequential Model\n",
    "    embedding_layer = Embedding(vocab_size,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "    model.add(embedding_layer) # Add the Embedding layers to \n",
    "    model.add(SimpleRNN(embedding_dim, return_sequences = False))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='mean_squared_error'\n",
    "              ,optimizer='rmsprop'\n",
    "              ,metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Word2Vec model\n"
     ]
    }
   ],
   "source": [
    "# Load the Pretrained Word Vector from Gensim\n",
    "wordvec = Word2Vec.load(vector_file_name_path) # Load the model from the vector_file_name\n",
    "wordvec.wv.init_sims(replace=True)\n",
    "print('Loaded Word2Vec model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  968009\n"
     ]
    }
   ],
   "source": [
    "# Get Vocabulary Size\n",
    "vocab_size = len(wordvec.wv.vocab)\n",
    "print('Vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train_data\n",
    "fname = os.path.join(train_file_path,train_file_name)\n",
    "x_train , y_train = load_data(fname,wordvec) # Preprocess the input data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Y for Evaluation\n",
    "save_file_name = './../model/Evaluation/' + type_of_Word2Vec_model + '_Y_label.npy'\n",
    "np.save(save_file_name, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = Word2VecTOEmbeddingMatrix(wordvec,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "model = init_rnn_model(vocab_size, embedding_dim, embedding_matrix, MAX_SEQUENCE_LENGTH) # Get model architecture\n",
    "history = model.fit(x_train , y_train, epochs = num_of_epochs , batch_size = batch_size, validation_split = 0.1)\n",
    "print('Training Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_weights(save_model_path)\n",
    "print('Saved model to: ', save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
